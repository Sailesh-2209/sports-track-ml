{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bbdbdc8-8d5c-490f-9d46-ab93aa684393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.xception import Xception\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0d60f2f-6910-4e05-9c1b-d9380069d261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# CONSTANTS RELATED TO VIDEO DATA\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "# directory where videos of different shots are stored\n",
    "VIDEO_DIRECTORY = \"videos\"\n",
    "# path to each one of the directories containing vidoes belonging to different shot types\n",
    "CATEGORY_DIRECTORIES = glob(os.path.join(VIDEO_DIRECTORY, \"*\"))\n",
    "# categories or shot types\n",
    "CATEGORIES = [x.split(os.sep)[-1] for x in CATEGORY_DIRECTORIES]\n",
    "# number of categories (also equal to the number of nuerons in the output layer)\n",
    "NUM_CATEGORIES = len(CATEGORIES)\n",
    "# training data is generated from the video clips and saved as a CSV file\n",
    "TRAIN_CSV_FILENAME = \"train_data.csv\"\n",
    "# testing data is generated from the video clips and saved as a CSV file\n",
    "TEST_CSV_FILENAME = \"test_data.csv\"\n",
    "IM_WIDTH = 240\n",
    "IM_HEIGHT = 135\n",
    "FRAME_RATE = 30\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# CONSTANTS RELATED TO VIDEO DATA\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "# name of the model which saves the optimal weights after training\n",
    "# 320 x 180 is chosen so that it has the same aspect ratio as the original vid (1920 x 1080)\n",
    "MODEL_NAME = \"weights.hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba397fe5-2169-4e67-a9c0-d42b7123899d",
   "metadata": {},
   "source": [
    "# Rename Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceca23af-e17b-4f1e-ac46-4c5cf80d9034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renaming videos...\n"
     ]
    }
   ],
   "source": [
    "print(\"Renaming videos...\")\n",
    "for i in range(NUM_CATEGORIES):\n",
    "    videos = glob(os.path.join(CATEGORY_DIRECTORIES[i], \"*\"))\n",
    "    category = CATEGORIES[i]\n",
    "    counter = 0\n",
    "    for video in videos:\n",
    "        counter += 1\n",
    "        new_name = f\"videos\\\\{category}\\\\{category}_{counter:05d}.mp4\"\n",
    "        os.rename(video, new_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48460441-dfe0-4efa-bf3d-771144f97785",
   "metadata": {},
   "source": [
    "# Convert videos to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ac4993b-f058-4741-ad98-7f108f3fb9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting videos to images...\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "print(\"Converting videos to images...\")\n",
    "for i in range(NUM_CATEGORIES):\n",
    "    videos = glob(os.path.join(CATEGORY_DIRECTORIES[i], \"*\"))\n",
    "    counter = 0\n",
    "    for video in videos:\n",
    "        cap = cv2.VideoCapture(video)\n",
    "        frames = 0\n",
    "        # loop until there are no frames left or the number of frames exceeds FRAME_RATE (30)\n",
    "        while True and frames < FRAME_RATE:\n",
    "            frames += 1\n",
    "            counter += 1\n",
    "            ret, frame = cap.read()\n",
    "            if (not ret):  # no more frames are left in the video\n",
    "                break\n",
    "            # create a directory called images if it doesn't already exist\n",
    "            if not os.path.exists(\"images\"):\n",
    "                os.mkdir(\"images\")\n",
    "            img_dir = os.path.join(\n",
    "                os.getcwd(), \"images\", CATEGORIES[i])\n",
    "            # create sub-directory inside images with the label name if it doesn't already exist\n",
    "            if not os.path.exists(img_dir):\n",
    "                os.mkdir(img_dir)\n",
    "            img_name = f\"{CATEGORIES[i]}_{counter:05d}.jpg\"\n",
    "            img_path = os.path.join(img_dir, img_name)\n",
    "            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            resized_gray_frame = cv2.resize(\n",
    "                gray_frame, (IM_WIDTH, IM_HEIGHT), interpolation=cv2.INTER_AREA)\n",
    "            if not cv2.imwrite(img_path, resized_gray_frame):\n",
    "                raise Exception(\"Failed to write image\")\n",
    "            images.append((img_path, CATEGORIES[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e253fed-46c3-4af3-a537-2558ac01c693",
   "metadata": {},
   "source": [
    "# Split into test and train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c8cd060-aa6d-418f-b2df-12f6306915c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting images into training set and testing set...\n"
     ]
    }
   ],
   "source": [
    "print(\"Splitting images into training set and testing set...\")\n",
    "X = []\n",
    "y = []\n",
    "for (img_path, label) in images:\n",
    "    X.append(img_path)\n",
    "    y.append(label)\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "# the stratify parameter is used to make sure that the distribution of each class is similar in test and train sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff6954a-728e-4a6d-944d-e98579dd2b4c",
   "metadata": {},
   "source": [
    "# Preprocess images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc5ffd64-0639-490c-809a-27ebd10aaa5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2889, 240, 135, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_loader = lambda x : image.load_img(x, target_size=(IM_WIDTH, IM_HEIGHT, 3))\n",
    "image_to_array = lambda x : image.img_to_array(x)\n",
    "image_normalize = lambda x : x / 255.0\n",
    "\n",
    "temp_train = []\n",
    "temp_test = []\n",
    "\n",
    "for img in X_train:\n",
    "    img = image_loader(img)\n",
    "    img = image_to_array(img)\n",
    "    img = image_normalize(img)\n",
    "    temp_train.append(img)\n",
    "\n",
    "for img in X_test:\n",
    "    img = image_loader(img)\n",
    "    img = image_to_array(img)\n",
    "    img = image_normalize(img)\n",
    "    temp_test.append(img)\n",
    "    \n",
    "X_train = np.array(temp_train)\n",
    "X_test = np.array(temp_test)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19cbc229-a4ba-4e63-b676-3fe4de776b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(CATEGORIES)\n",
    "\n",
    "y_test_lab = le.transform(y_test)\n",
    "y_train_lab = le.transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5f398f3-956f-451a-a013-c95f91595b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights=\"imagenet\", include_top=False)\n",
    "\n",
    "X_train = base_model.predict(X_train, batch_size=16)\n",
    "X_test = base_model.predict(X_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71b5d7e4-6095-46eb-93be-6a74cb9e8268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2889, 7, 4, 512)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4d8ce97-2110-40f2-a112-e7f428986b53",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m X_train \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mreshape(\n\u001b[1;32m----> 2\u001b[0m     X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m*\u001b[39m X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m])\n\u001b[0;32m      3\u001b[0m X_test \u001b[38;5;241m=\u001b[39m X_test\u001b[38;5;241m.\u001b[39mreshape(\n\u001b[0;32m      4\u001b[0m     X_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], X_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m X_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m*\u001b[39m X_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m])\n\u001b[0;32m      6\u001b[0m maxval \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mmax()\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(\n",
    "    X_train.shape[0], X_train.shape[1] * X_train.shape[2] * X_train.shape[3])\n",
    "X_test = X_test.reshape(\n",
    "    X_test.shape[0], X_test.shape[1] * X_test.shape[2] * X_test.shape[3])\n",
    "\n",
    "maxval = X_train.max()\n",
    "X_train = X_train / maxval\n",
    "X_test = X_test / maxval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c25a4fa-9352-44ce-b951-3c19e4ef0a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2889, 14336)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45aadee4-c503-4e59-a121-b89088c1a16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (16, 1, 256)              14943232  \n",
      "                                                                 \n",
      " dense_15 (Dense)            (16, 1, 1024)             263168    \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (16, 1, 1024)             0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (16, 1, 512)              524800    \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (16, 1, 512)              0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (16, 1, 256)              131328    \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (16, 1, 256)              0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (16, 1, 128)              32896     \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (16, 1, 128)              0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (16, 1, 5)                645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,896,069\n",
      "Trainable params: 15,896,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256,dropout=0.2, batch_input_shape=(16, 1, X_train.shape[1]), return_sequences=True))\n",
    "model.add(Dense(1024, activation=\"relu\", input_shape=(X_train.shape[1],)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NUM_CATEGORIES, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0a75d2e-7bc3-4fbb-ae25-0b699bb686cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\saile\\Documents\\Sailesh\\Programming\\Projects\\SportsTrack\\Application\\MachineLearning\\ShotClassification\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\saile\\Documents\\Sailesh\\Programming\\Projects\\SportsTrack\\Application\\MachineLearning\\ShotClassification\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\saile\\Documents\\Sailesh\\Programming\\Projects\\SportsTrack\\Application\\MachineLearning\\ShotClassification\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\saile\\Documents\\Sailesh\\Programming\\Projects\\SportsTrack\\Application\\MachineLearning\\ShotClassification\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\saile\\Documents\\Sailesh\\Programming\\Projects\\SportsTrack\\Application\\MachineLearning\\ShotClassification\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\saile\\Documents\\Sailesh\\Programming\\Projects\\SportsTrack\\Application\\MachineLearning\\ShotClassification\\venv\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_4\" is incompatible with the layer: expected shape=(None, 1, 14336), found shape=(None, 14336)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(MODEL_NAME, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdam\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\Sailesh\\Programming\\Projects\\SportsTrack\\Application\\MachineLearning\\ShotClassification\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\Documents\\Sailesh\\Programming\\Projects\\SportsTrack\\Application\\MachineLearning\\ShotClassification\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m   1148\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\saile\\Documents\\Sailesh\\Programming\\Projects\\SportsTrack\\Application\\MachineLearning\\ShotClassification\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\saile\\Documents\\Sailesh\\Programming\\Projects\\SportsTrack\\Application\\MachineLearning\\ShotClassification\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\saile\\Documents\\Sailesh\\Programming\\Projects\\SportsTrack\\Application\\MachineLearning\\ShotClassification\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\saile\\Documents\\Sailesh\\Programming\\Projects\\SportsTrack\\Application\\MachineLearning\\ShotClassification\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\saile\\Documents\\Sailesh\\Programming\\Projects\\SportsTrack\\Application\\MachineLearning\\ShotClassification\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\saile\\Documents\\Sailesh\\Programming\\Projects\\SportsTrack\\Application\\MachineLearning\\ShotClassification\\venv\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_4\" is incompatible with the layer: expected shape=(None, 1, 14336), found shape=(None, 14336)\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(MODEL_NAME, save_best_only=True, monitor=\"val_loss\", mode=\"min\")\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, epochs=200, validation_data=(\n",
    "    X_test, y_test), callbacks=[checkpoint], batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609c2256-646d-438e-af32-7532f0b49a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b4e356-1500-4a8c-8693-cf9c0f6ff18a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
